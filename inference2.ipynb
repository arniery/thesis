{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arniery/thesis/blob/main/inference2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text-to-Speech Accent Conversion with Tacotron2, AutoVC, and HifiGAN\n",
        "\n",
        "This is an English female voice TTS demo using open source projects [BogiHsu/Tacotron2-PyTorch](https://github.com/BogiHsu/Tacotron2-PyTorch) and [jik876/hifi-gan](https://github.com/jik876/hifi-gan).\n",
        "\n",
        "Please enable GPU acceleration in Colab before you start running the code."
      ],
      "metadata": {
        "id": "3qb1435p6OEz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rof5nB25HD4"
      },
      "source": [
        "## Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBB0-ki_5HD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0ff2d6-1f6a-4dba-8984-1576ff4a93ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tacotron2-PyTorch'...\n",
            "remote: Enumerating objects: 395, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 395 (delta 96), reused 98 (delta 80), pack-reused 263 (from 1)\u001b[K\n",
            "Receiving objects: 100% (395/395), 2.97 MiB | 7.13 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 2)) (1.16.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 4)) (7.5.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 5)) (0.11.0)\n",
            "Collecting Unidecode (from -r Tacotron2-PyTorch/requirements.txt (line 6))\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r Tacotron2-PyTorch/requirements.txt (line 7)) (3.10.0)\n",
            "Collecting tensorboardX (from -r Tacotron2-PyTorch/requirements.txt (line 8))\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->-r Tacotron2-PyTorch/requirements.txt (line 4)) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->-r Tacotron2-PyTorch/requirements.txt (line 4)) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX->-r Tacotron2-PyTorch/requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r Tacotron2-PyTorch/requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r Tacotron2-PyTorch/requirements.txt (line 5)) (2025.8.3)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode, tensorboardX\n",
            "Successfully installed Unidecode-1.4.0 tensorboardX-2.6.4\n",
            "Cloning into 'hifi-gan'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
            "Receiving objects: 100% (48/48), 620.94 KiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BogiHsu/Tacotron2-PyTorch.git\n",
        "!pip install -r Tacotron2-PyTorch/requirements.txt\n",
        "!git clone https://github.com/jik876/hifi-gan.git\n",
        "!mkdir -p mel_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whZkDydI5HD9"
      },
      "source": [
        "## Download Tacotron2 pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbbOs-sT5HD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5dd647-b6f4-405c-c3bc-dd23e8878716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-19 18:42:12--  https://github.com/BogiHsu/Tacotron2-PyTorch/releases/download/lj-200k-b512/ckpt_200000\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/189844891/a8fe7134-b9f9-4152-b571-386f437a7c87?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-19T19%3A21%3A46Z&rscd=attachment%3B+filename%3Dckpt_200000&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-19T18%3A21%3A45Z&ske=2025-08-19T19%3A21%3A46Z&sks=b&skv=2018-11-09&sig=vPXTHBtwsDY5STd9A86YY0ymcwX53Y8HNk42LrLmhFg%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTYyOTIzMiwibmJmIjoxNzU1NjI4OTMyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.bBkk-R8b8-7C8dCVhRN5fJKI5to8uRFqz3Rocimq16k&response-content-disposition=attachment%3B%20filename%3Dckpt_200000&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-08-19 18:42:12--  https://release-assets.githubusercontent.com/github-production-release-asset/189844891/a8fe7134-b9f9-4152-b571-386f437a7c87?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-19T19%3A21%3A46Z&rscd=attachment%3B+filename%3Dckpt_200000&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-19T18%3A21%3A45Z&ske=2025-08-19T19%3A21%3A46Z&sks=b&skv=2018-11-09&sig=vPXTHBtwsDY5STd9A86YY0ymcwX53Y8HNk42LrLmhFg%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTYyOTIzMiwibmJmIjoxNzU1NjI4OTMyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.bBkk-R8b8-7C8dCVhRN5fJKI5to8uRFqz3Rocimq16k&response-content-disposition=attachment%3B%20filename%3Dckpt_200000&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 341853943 (326M) [application/octet-stream]\n",
            "Saving to: ‘Tacotron2-PyTorch/ckpt_200000’\n",
            "\n",
            "Tacotron2-PyTorch/c 100%[===================>] 326.02M  39.5MB/s    in 7.7s    \n",
            "\n",
            "2025-08-19 18:42:20 (42.4 MB/s) - ‘Tacotron2-PyTorch/ckpt_200000’ saved [341853943/341853943]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/BogiHsu/Tacotron2-PyTorch/releases/download/lj-200k-b512/ckpt_200000 -O Tacotron2-PyTorch/ckpt_200000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTcGBEfG5HD-"
      },
      "source": [
        "## Download HifiGAN pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gH6vR6045HD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e014d6dc-b18a-4a72-e5ab-966cdf1a5dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=1aDh576AEYA5eTjhx7sew1qcCM_Y526jc&export=download\n",
            "To: /content/hifi-gan/config.json\n",
            "100%|██████████| 795/795 [00:00<00:00, 3.00MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=14NENd4equCBLyyCSke114Mv6YR_j_uFs&export=download\n",
            "To: /content/hifi-gan/generator_v1\n",
            "100%|██████████| 55.8M/55.8M [00:01<00:00, 50.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "dl = {'hifi-gan/config.json': 'https://drive.google.com/u/1/uc?id=1aDh576AEYA5eTjhx7sew1qcCM_Y526jc&export=download',\n",
        "      'hifi-gan/generator_v1': 'https://drive.google.com/u/1/uc?id=14NENd4equCBLyyCSke114Mv6YR_j_uFs&export=download'}\n",
        "for k in dl:\n",
        "    gdown.download(dl[k], k)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aTf9-dy8nlG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVSo2j5sU7Gf",
        "outputId": "d47fa582-74e7-4b6e-df43-9d46967d194e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/autovc_data/autovc.ckpt ./\n",
        "!cp -r /content/drive/MyDrive/autovc_data/spmel ./\n",
        "!cp -r /content/drive/MyDrive/autovc_data/wav16k ./\n"
      ],
      "metadata": {
        "id": "IjB2PCGgrFQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modifying/fine-tuning hifi-gan"
      ],
      "metadata": {
        "id": "jo4p4hLH19Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Paths to your AutoVC-generated data\n",
        "mel_root = '/content/spmel/female_speaker'\n",
        "wav_root = '/content/wav16k/female_speaker'\n",
        "filelist_dir = '/content/hifi-gan/filelists'\n",
        "train_file = os.path.join(filelist_dir, 'training.txt')\n",
        "val_file = os.path.join(filelist_dir, 'validation.txt')\n",
        "\n",
        "lines = []\n",
        "\n",
        "# Pair up mel and wav files\n",
        "for fname in sorted(os.listdir(mel_root)):\n",
        "    if not fname.endswith('.npy'):\n",
        "        continue\n",
        "    mel_path = os.path.join(mel_root, fname)\n",
        "\n",
        "    # FIX: safer wav file naming\n",
        "    wav_fname = os.path.splitext(fname)[0] + '.wav'\n",
        "    wav_path = os.path.join(wav_root, wav_fname)\n",
        "\n",
        "    if os.path.exists(wav_path):\n",
        "        lines.append(f\"{mel_path}|{wav_path}\")\n",
        "    else:\n",
        "        print(f\"Warning: Missing wav file for {fname}\")\n",
        "\n",
        "# Shuffle and split (95% train, 5% validation)\n",
        "random.shuffle(lines)\n",
        "split_idx = int(0.95 * len(lines))\n",
        "train_lines = lines[:split_idx]\n",
        "val_lines = lines[split_idx:]\n",
        "\n",
        "# Write to file\n",
        "os.makedirs(filelist_dir, exist_ok=True)\n",
        "\n",
        "with open(train_file, 'w') as f:\n",
        "    f.write('\\n'.join(train_lines))\n",
        "\n",
        "with open(val_file, 'w') as f:\n",
        "    f.write('\\n'.join(val_lines))\n",
        "\n",
        "print(f\"Training file saved to: {train_file}, total: {len(train_lines)}\")\n",
        "print(f\"Validation file saved to: {val_file}, total: {len(val_lines)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYdGriKF9Lpx",
        "outputId": "7a09eba3-17bb-463f-e7ce-db7a2b7c2cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing wav file for train_hindifullfemale_00069_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_00111_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_00406_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_00888_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_01074_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_01326_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_01563_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_01895_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_02266_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_02771_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_03303_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_03604_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_03614_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_04345_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_04500_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_04652_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_05220_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_05737_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_06022_16k (1).npy\n",
            "Warning: Missing wav file for train_hindifullfemale_06032_16k (1).npy\n",
            "Training file saved to: /content/hifi-gan/filelists/training.txt, total: 6213\n",
            "Validation file saved to: /content/hifi-gan/filelists/validation.txt, total: 328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "flat_config = {\n",
        "  \"batch_size\": 32,                # Double your current batch size if GPU memory allows\n",
        "  \"learning_rate\": 0.0002,\n",
        "  \"adam_b1\": 0.8,\n",
        "  \"adam_b2\": 0.99,\n",
        "  \"lr_decay\": 0.999,\n",
        "  \"seed\": 1234,\n",
        "  \"fp16_run\": True,                # Enable mixed-precision for faster training\n",
        "  \"sampling_rate\": 16000,\n",
        "  \"segment_size\": 4096,            # Smaller segments = faster per-step computation\n",
        "  \"filter_length\": 1024,\n",
        "  \"hop_size\": 256,\n",
        "  \"win_size\": 1024,\n",
        "  \"n_fft\": 1024,\n",
        "  \"num_mels\": 80,\n",
        "  \"fmin\": 90,\n",
        "  \"fmax\": 7600,\n",
        "  \"fmax_for_loss\": None,\n",
        "  \"upsample_rates\": [8, 8, 2, 2],\n",
        "  \"upsample_kernel_sizes\": [16, 16, 4, 4],\n",
        "  \"upsample_initial_channel\": 512,\n",
        "  \"resblock\": \"1\",\n",
        "  \"resblock_kernel_sizes\": [3, 7, 11],\n",
        "  \"resblock_dilation_sizes\": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "  \"resblock_initial_channel\": 256,\n",
        "  \"num_workers\": 4,                # DataLoader workers\n",
        "  \"num_gpus\": 1,\n",
        "  \"dist_config\": {\n",
        "    \"dist_backend\": \"nccl\",\n",
        "    \"dist_url\": \"tcp://localhost:54321\",\n",
        "    \"world_size\": 1\n",
        "  }\n",
        "}\n",
        "\n",
        "with open(\"/content/hifi-gan/config_autovc.json\", \"w\") as f:\n",
        "    json.dump(flat_config, f, indent=4)\n",
        "\n",
        "print(\"Flat config saved to /content/hifi-gan/config_autovc.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsSWqaGO9yfW",
        "outputId": "5b933c20-10e5-4ffb-e09e-4f7f6870d861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat config saved to /content/hifi-gan/config_autovc.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/autovc_data /content/"
      ],
      "metadata": {
        "id": "O5W-Gq5Ogi3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tuning\n",
        "%cd /content/hifi-gan\n",
        "\n",
        "!python train.py \\\n",
        "  --config config_autovc.json \\\n",
        "  --input_training_file filelists/training.txt \\\n",
        "  --input_validation_file filelists/validation.txt \\\n",
        "  --input_wavs_dir /content/wav16k/female_speaker \\\n",
        "  --input_mels_dir /content/spmel/female_speaker \\\n",
        "  --training_epochs 12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPQBtWdADnvr",
        "outputId": "70fff6b0-8d4f-4f89-ffc5-1db9d4aa64ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hifi-gan\n",
            "2025-08-17 21:24:59.454058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755465899.752803   15261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755465899.834352   15261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755465900.444271   15261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755465900.444323   15261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755465900.444327   15261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755465900.444331   15261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-17 21:25:00.499170: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Initializing Training Process..\n",
            "Batch size per GPU : 32\n",
            "Generator(\n",
            "  (conv_pre): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "  (ups): ModuleList(\n",
            "    (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n",
            "    (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n",
            "    (2): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
            "    (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
            "  )\n",
            "  (resblocks): ModuleList(\n",
            "    (0): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      )\n",
            "    )\n",
            "    (1): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
            "        (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "      )\n",
            "    )\n",
            "    (2): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
            "        (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "      )\n",
            "    )\n",
            "    (3): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      )\n",
            "    )\n",
            "    (4): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
            "        (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "      )\n",
            "    )\n",
            "    (5): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
            "        (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "      )\n",
            "    )\n",
            "    (6): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      )\n",
            "    )\n",
            "    (7): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
            "        (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "      )\n",
            "    )\n",
            "    (8): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
            "        (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "      )\n",
            "    )\n",
            "    (9): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "        (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "        (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      )\n",
            "    )\n",
            "    (10): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "        (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
            "        (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "      )\n",
            "    )\n",
            "    (11): ResBlock1(\n",
            "      (convs1): ModuleList(\n",
            "        (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
            "        (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
            "      )\n",
            "      (convs2): ModuleList(\n",
            "        (0-2): 3 x Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            ")\n",
            "checkpoints directory :  cp_hifigan\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch: 1\n",
            "Steps : 0, Gen Loss Total : 355.514, Mel-Spec. Error : 7.742, s/b : 32.735\n",
            "Steps : 5, Gen Loss Total : 176.074, Mel-Spec. Error : 3.840, s/b : 1.958\n",
            "Steps : 10, Gen Loss Total : 59.181, Mel-Spec. Error : 1.148, s/b : 1.988\n",
            "Steps : 15, Gen Loss Total : 49.011, Mel-Spec. Error : 0.486, s/b : 1.998\n",
            "Steps : 20, Gen Loss Total : 50.907, Mel-Spec. Error : 0.457, s/b : 2.027\n",
            "Steps : 25, Gen Loss Total : 46.022, Mel-Spec. Error : 0.422, s/b : 2.046\n",
            "Steps : 30, Gen Loss Total : 48.148, Mel-Spec. Error : 0.407, s/b : 2.069\n",
            "Steps : 35, Gen Loss Total : 47.798, Mel-Spec. Error : 0.380, s/b : 2.091\n",
            "Steps : 40, Gen Loss Total : 46.783, Mel-Spec. Error : 0.362, s/b : 2.108\n",
            "Steps : 45, Gen Loss Total : 48.335, Mel-Spec. Error : 0.397, s/b : 2.097\n",
            "Steps : 50, Gen Loss Total : 48.471, Mel-Spec. Error : 0.401, s/b : 2.081\n",
            "Steps : 55, Gen Loss Total : 48.390, Mel-Spec. Error : 0.396, s/b : 2.066\n",
            "Steps : 60, Gen Loss Total : 46.992, Mel-Spec. Error : 0.369, s/b : 2.053\n",
            "Steps : 65, Gen Loss Total : 48.486, Mel-Spec. Error : 0.390, s/b : 2.056\n",
            "Steps : 70, Gen Loss Total : 47.320, Mel-Spec. Error : 0.369, s/b : 2.060\n",
            "Steps : 75, Gen Loss Total : 47.228, Mel-Spec. Error : 0.366, s/b : 2.056\n",
            "Steps : 80, Gen Loss Total : 48.152, Mel-Spec. Error : 0.385, s/b : 2.066\n",
            "Steps : 85, Gen Loss Total : 47.628, Mel-Spec. Error : 0.372, s/b : 2.074\n",
            "Steps : 90, Gen Loss Total : 47.696, Mel-Spec. Error : 0.371, s/b : 2.075\n",
            "Steps : 95, Gen Loss Total : 48.246, Mel-Spec. Error : 0.385, s/b : 2.072\n",
            "Steps : 100, Gen Loss Total : 47.429, Mel-Spec. Error : 0.365, s/b : 2.068\n",
            "Steps : 105, Gen Loss Total : 47.214, Mel-Spec. Error : 0.361, s/b : 2.062\n",
            "Steps : 110, Gen Loss Total : 47.013, Mel-Spec. Error : 0.362, s/b : 2.062\n",
            "Steps : 115, Gen Loss Total : 47.869, Mel-Spec. Error : 0.376, s/b : 2.065\n",
            "Steps : 120, Gen Loss Total : 45.932, Mel-Spec. Error : 0.332, s/b : 2.066\n",
            "Steps : 125, Gen Loss Total : 45.720, Mel-Spec. Error : 0.329, s/b : 2.065\n",
            "Steps : 130, Gen Loss Total : 45.663, Mel-Spec. Error : 0.331, s/b : 2.067\n",
            "Steps : 135, Gen Loss Total : 46.927, Mel-Spec. Error : 0.352, s/b : 2.061\n",
            "Steps : 140, Gen Loss Total : 46.212, Mel-Spec. Error : 0.338, s/b : 2.062\n",
            "Steps : 145, Gen Loss Total : 47.260, Mel-Spec. Error : 0.362, s/b : 2.066\n",
            "Steps : 150, Gen Loss Total : 46.914, Mel-Spec. Error : 0.353, s/b : 2.061\n",
            "Steps : 155, Gen Loss Total : 45.603, Mel-Spec. Error : 0.326, s/b : 2.064\n",
            "Steps : 160, Gen Loss Total : 45.442, Mel-Spec. Error : 0.323, s/b : 2.066\n",
            "Steps : 165, Gen Loss Total : 46.100, Mel-Spec. Error : 0.338, s/b : 2.070\n",
            "Steps : 170, Gen Loss Total : 45.598, Mel-Spec. Error : 0.325, s/b : 2.070\n",
            "Steps : 175, Gen Loss Total : 46.899, Mel-Spec. Error : 0.352, s/b : 2.066\n",
            "Steps : 180, Gen Loss Total : 45.118, Mel-Spec. Error : 0.315, s/b : 2.065\n",
            "Steps : 185, Gen Loss Total : 45.305, Mel-Spec. Error : 0.321, s/b : 2.068\n",
            "Steps : 190, Gen Loss Total : 45.979, Mel-Spec. Error : 0.332, s/b : 2.065\n",
            "Time taken for epoch 1 is 380 sec\n",
            "\n",
            "Epoch: 2\n",
            "Steps : 195, Gen Loss Total : 46.248, Mel-Spec. Error : 0.339, s/b : 2.058\n",
            "Steps : 200, Gen Loss Total : 45.765, Mel-Spec. Error : 0.329, s/b : 2.066\n",
            "Steps : 205, Gen Loss Total : 45.686, Mel-Spec. Error : 0.332, s/b : 2.064\n",
            "Steps : 210, Gen Loss Total : 45.811, Mel-Spec. Error : 0.332, s/b : 2.069\n",
            "Steps : 215, Gen Loss Total : 46.441, Mel-Spec. Error : 0.344, s/b : 2.068\n",
            "Steps : 220, Gen Loss Total : 45.756, Mel-Spec. Error : 0.328, s/b : 2.064\n",
            "Steps : 225, Gen Loss Total : 45.730, Mel-Spec. Error : 0.329, s/b : 2.065\n",
            "Steps : 230, Gen Loss Total : 45.438, Mel-Spec. Error : 0.322, s/b : 2.069\n",
            "Steps : 235, Gen Loss Total : 46.265, Mel-Spec. Error : 0.343, s/b : 2.065\n",
            "Steps : 240, Gen Loss Total : 45.205, Mel-Spec. Error : 0.318, s/b : 2.068\n",
            "Steps : 245, Gen Loss Total : 45.526, Mel-Spec. Error : 0.322, s/b : 2.067\n",
            "Steps : 250, Gen Loss Total : 45.528, Mel-Spec. Error : 0.323, s/b : 2.067\n",
            "Steps : 255, Gen Loss Total : 45.741, Mel-Spec. Error : 0.329, s/b : 2.069\n",
            "Steps : 260, Gen Loss Total : 45.456, Mel-Spec. Error : 0.321, s/b : 2.070\n",
            "Steps : 265, Gen Loss Total : 45.205, Mel-Spec. Error : 0.317, s/b : 2.066\n",
            "Steps : 270, Gen Loss Total : 45.522, Mel-Spec. Error : 0.330, s/b : 2.067\n",
            "Steps : 275, Gen Loss Total : 45.748, Mel-Spec. Error : 0.334, s/b : 2.064\n",
            "Steps : 280, Gen Loss Total : 46.378, Mel-Spec. Error : 0.344, s/b : 2.059\n",
            "Steps : 285, Gen Loss Total : 45.280, Mel-Spec. Error : 0.322, s/b : 2.070\n",
            "Steps : 290, Gen Loss Total : 45.793, Mel-Spec. Error : 0.327, s/b : 2.066\n",
            "Steps : 295, Gen Loss Total : 45.895, Mel-Spec. Error : 0.331, s/b : 2.065\n",
            "Steps : 300, Gen Loss Total : 45.822, Mel-Spec. Error : 0.331, s/b : 2.067\n",
            "Steps : 305, Gen Loss Total : 44.150, Mel-Spec. Error : 0.296, s/b : 2.067\n",
            "Steps : 310, Gen Loss Total : 44.788, Mel-Spec. Error : 0.312, s/b : 2.061\n",
            "Steps : 315, Gen Loss Total : 45.225, Mel-Spec. Error : 0.317, s/b : 2.068\n",
            "Steps : 320, Gen Loss Total : 44.738, Mel-Spec. Error : 0.309, s/b : 2.071\n",
            "Steps : 325, Gen Loss Total : 44.833, Mel-Spec. Error : 0.312, s/b : 2.061\n",
            "Steps : 330, Gen Loss Total : 44.642, Mel-Spec. Error : 0.307, s/b : 2.068\n",
            "Steps : 335, Gen Loss Total : 44.711, Mel-Spec. Error : 0.307, s/b : 2.064\n",
            "Steps : 340, Gen Loss Total : 44.975, Mel-Spec. Error : 0.315, s/b : 2.063\n",
            "Steps : 345, Gen Loss Total : 44.520, Mel-Spec. Error : 0.302, s/b : 2.073\n",
            "Steps : 350, Gen Loss Total : 45.285, Mel-Spec. Error : 0.321, s/b : 2.073\n",
            "Steps : 355, Gen Loss Total : 45.255, Mel-Spec. Error : 0.319, s/b : 2.074\n",
            "Steps : 360, Gen Loss Total : 44.352, Mel-Spec. Error : 0.299, s/b : 2.072\n",
            "Steps : 365, Gen Loss Total : 44.655, Mel-Spec. Error : 0.310, s/b : 2.068\n",
            "Steps : 370, Gen Loss Total : 44.940, Mel-Spec. Error : 0.316, s/b : 2.063\n",
            "Steps : 375, Gen Loss Total : 43.737, Mel-Spec. Error : 0.289, s/b : 2.072\n",
            "Steps : 380, Gen Loss Total : 44.662, Mel-Spec. Error : 0.309, s/b : 2.071\n",
            "Steps : 385, Gen Loss Total : 45.029, Mel-Spec. Error : 0.315, s/b : 2.066\n",
            "Time taken for epoch 2 is 339 sec\n",
            "\n",
            "Epoch: 3\n",
            "Steps : 390, Gen Loss Total : 44.278, Mel-Spec. Error : 0.299, s/b : 2.067\n",
            "Steps : 395, Gen Loss Total : 44.955, Mel-Spec. Error : 0.313, s/b : 2.064\n",
            "Steps : 400, Gen Loss Total : 45.192, Mel-Spec. Error : 0.317, s/b : 2.066\n",
            "Steps : 405, Gen Loss Total : 44.134, Mel-Spec. Error : 0.300, s/b : 2.064\n",
            "Steps : 410, Gen Loss Total : 45.393, Mel-Spec. Error : 0.320, s/b : 2.066\n",
            "Steps : 415, Gen Loss Total : 44.205, Mel-Spec. Error : 0.294, s/b : 2.068\n",
            "Steps : 420, Gen Loss Total : 44.151, Mel-Spec. Error : 0.295, s/b : 2.065\n",
            "Steps : 425, Gen Loss Total : 44.389, Mel-Spec. Error : 0.300, s/b : 2.075\n",
            "Steps : 430, Gen Loss Total : 45.242, Mel-Spec. Error : 0.319, s/b : 2.069\n",
            "Steps : 435, Gen Loss Total : 44.209, Mel-Spec. Error : 0.298, s/b : 2.061\n",
            "Steps : 440, Gen Loss Total : 44.607, Mel-Spec. Error : 0.305, s/b : 2.069\n",
            "Steps : 445, Gen Loss Total : 43.854, Mel-Spec. Error : 0.293, s/b : 2.068\n",
            "Steps : 450, Gen Loss Total : 44.929, Mel-Spec. Error : 0.312, s/b : 2.065\n",
            "Steps : 455, Gen Loss Total : 44.467, Mel-Spec. Error : 0.308, s/b : 2.064\n",
            "Steps : 460, Gen Loss Total : 44.221, Mel-Spec. Error : 0.301, s/b : 2.070\n",
            "Steps : 465, Gen Loss Total : 43.251, Mel-Spec. Error : 0.274, s/b : 2.068\n",
            "Steps : 470, Gen Loss Total : 44.255, Mel-Spec. Error : 0.299, s/b : 2.062\n",
            "Steps : 475, Gen Loss Total : 43.763, Mel-Spec. Error : 0.283, s/b : 2.069\n",
            "Steps : 480, Gen Loss Total : 43.953, Mel-Spec. Error : 0.292, s/b : 2.064\n",
            "Steps : 485, Gen Loss Total : 44.483, Mel-Spec. Error : 0.305, s/b : 2.069\n",
            "Steps : 490, Gen Loss Total : 44.670, Mel-Spec. Error : 0.302, s/b : 2.065\n",
            "Steps : 495, Gen Loss Total : 43.944, Mel-Spec. Error : 0.290, s/b : 2.071\n",
            "Steps : 500, Gen Loss Total : 44.440, Mel-Spec. Error : 0.306, s/b : 2.068\n",
            "Steps : 505, Gen Loss Total : 44.492, Mel-Spec. Error : 0.305, s/b : 2.063\n",
            "Steps : 510, Gen Loss Total : 45.020, Mel-Spec. Error : 0.317, s/b : 2.067\n",
            "Steps : 515, Gen Loss Total : 43.995, Mel-Spec. Error : 0.294, s/b : 2.065\n",
            "Steps : 520, Gen Loss Total : 43.745, Mel-Spec. Error : 0.287, s/b : 2.059\n",
            "Steps : 525, Gen Loss Total : 43.885, Mel-Spec. Error : 0.289, s/b : 2.065\n",
            "Steps : 530, Gen Loss Total : 43.682, Mel-Spec. Error : 0.289, s/b : 2.066\n",
            "Steps : 535, Gen Loss Total : 43.549, Mel-Spec. Error : 0.286, s/b : 2.067\n",
            "Steps : 540, Gen Loss Total : 43.935, Mel-Spec. Error : 0.289, s/b : 2.068\n",
            "Steps : 545, Gen Loss Total : 44.850, Mel-Spec. Error : 0.312, s/b : 2.065\n",
            "Steps : 550, Gen Loss Total : 45.292, Mel-Spec. Error : 0.322, s/b : 2.066\n",
            "Steps : 555, Gen Loss Total : 43.703, Mel-Spec. Error : 0.289, s/b : 2.058\n",
            "Steps : 560, Gen Loss Total : 43.487, Mel-Spec. Error : 0.282, s/b : 2.065\n",
            "Steps : 565, Gen Loss Total : 45.184, Mel-Spec. Error : 0.321, s/b : 2.067\n",
            "Steps : 570, Gen Loss Total : 43.645, Mel-Spec. Error : 0.289, s/b : 2.050\n",
            "Steps : 575, Gen Loss Total : 43.515, Mel-Spec. Error : 0.286, s/b : 2.065\n",
            "Steps : 580, Gen Loss Total : 44.033, Mel-Spec. Error : 0.293, s/b : 2.072\n",
            "Time taken for epoch 3 is 338 sec\n",
            "\n",
            "Epoch: 4\n",
            "Steps : 585, Gen Loss Total : 42.754, Mel-Spec. Error : 0.271, s/b : 2.072\n",
            "Steps : 590, Gen Loss Total : 44.156, Mel-Spec. Error : 0.295, s/b : 2.070\n",
            "Steps : 595, Gen Loss Total : 43.375, Mel-Spec. Error : 0.276, s/b : 2.067\n",
            "Steps : 600, Gen Loss Total : 43.665, Mel-Spec. Error : 0.286, s/b : 2.061\n",
            "Steps : 605, Gen Loss Total : 43.814, Mel-Spec. Error : 0.286, s/b : 2.067\n",
            "Steps : 610, Gen Loss Total : 43.874, Mel-Spec. Error : 0.288, s/b : 2.069\n",
            "Steps : 615, Gen Loss Total : 43.943, Mel-Spec. Error : 0.287, s/b : 2.063\n",
            "Steps : 620, Gen Loss Total : 44.088, Mel-Spec. Error : 0.289, s/b : 2.068\n",
            "Steps : 625, Gen Loss Total : 43.776, Mel-Spec. Error : 0.287, s/b : 2.068\n",
            "Steps : 630, Gen Loss Total : 43.230, Mel-Spec. Error : 0.279, s/b : 2.068\n",
            "Steps : 635, Gen Loss Total : 43.656, Mel-Spec. Error : 0.283, s/b : 2.068\n",
            "Steps : 640, Gen Loss Total : 43.385, Mel-Spec. Error : 0.279, s/b : 2.067\n",
            "Steps : 645, Gen Loss Total : 44.413, Mel-Spec. Error : 0.299, s/b : 2.072\n",
            "Steps : 650, Gen Loss Total : 42.916, Mel-Spec. Error : 0.269, s/b : 2.068\n",
            "Steps : 655, Gen Loss Total : 43.576, Mel-Spec. Error : 0.283, s/b : 2.070\n",
            "Steps : 660, Gen Loss Total : 42.984, Mel-Spec. Error : 0.273, s/b : 2.066\n",
            "Steps : 665, Gen Loss Total : 43.933, Mel-Spec. Error : 0.290, s/b : 2.074\n",
            "Steps : 670, Gen Loss Total : 43.071, Mel-Spec. Error : 0.273, s/b : 2.068\n",
            "Steps : 675, Gen Loss Total : 42.598, Mel-Spec. Error : 0.263, s/b : 2.071\n",
            "Steps : 680, Gen Loss Total : 43.605, Mel-Spec. Error : 0.275, s/b : 2.067\n",
            "Steps : 685, Gen Loss Total : 42.877, Mel-Spec. Error : 0.268, s/b : 2.064\n",
            "Steps : 690, Gen Loss Total : 42.373, Mel-Spec. Error : 0.260, s/b : 2.072\n",
            "Steps : 695, Gen Loss Total : 42.142, Mel-Spec. Error : 0.251, s/b : 2.066\n",
            "Steps : 700, Gen Loss Total : 43.558, Mel-Spec. Error : 0.279, s/b : 2.067\n",
            "Steps : 705, Gen Loss Total : 43.130, Mel-Spec. Error : 0.273, s/b : 2.068\n",
            "Steps : 710, Gen Loss Total : 42.395, Mel-Spec. Error : 0.256, s/b : 2.073\n",
            "Steps : 715, Gen Loss Total : 42.345, Mel-Spec. Error : 0.256, s/b : 2.073\n",
            "Steps : 720, Gen Loss Total : 42.321, Mel-Spec. Error : 0.259, s/b : 2.068\n",
            "Steps : 725, Gen Loss Total : 41.904, Mel-Spec. Error : 0.244, s/b : 2.070\n",
            "Steps : 730, Gen Loss Total : 42.497, Mel-Spec. Error : 0.258, s/b : 2.067\n",
            "Steps : 735, Gen Loss Total : 42.748, Mel-Spec. Error : 0.263, s/b : 2.072\n",
            "Steps : 740, Gen Loss Total : 41.781, Mel-Spec. Error : 0.249, s/b : 2.061\n",
            "Steps : 745, Gen Loss Total : 41.499, Mel-Spec. Error : 0.235, s/b : 2.075\n",
            "Steps : 750, Gen Loss Total : 42.290, Mel-Spec. Error : 0.253, s/b : 2.070\n",
            "Steps : 755, Gen Loss Total : 42.229, Mel-Spec. Error : 0.249, s/b : 2.068\n",
            "Steps : 760, Gen Loss Total : 42.247, Mel-Spec. Error : 0.248, s/b : 2.074\n",
            "Steps : 765, Gen Loss Total : 41.953, Mel-Spec. Error : 0.246, s/b : 2.076\n",
            "Steps : 770, Gen Loss Total : 42.464, Mel-Spec. Error : 0.254, s/b : 2.076\n",
            "Steps : 775, Gen Loss Total : 42.094, Mel-Spec. Error : 0.251, s/b : 2.069\n",
            "Time taken for epoch 4 is 339 sec\n",
            "\n",
            "Epoch: 5\n",
            "Steps : 780, Gen Loss Total : 41.741, Mel-Spec. Error : 0.242, s/b : 2.076\n",
            "Steps : 785, Gen Loss Total : 41.769, Mel-Spec. Error : 0.246, s/b : 2.073\n",
            "Steps : 790, Gen Loss Total : 41.310, Mel-Spec. Error : 0.236, s/b : 2.075\n",
            "Steps : 795, Gen Loss Total : 41.748, Mel-Spec. Error : 0.247, s/b : 2.070\n",
            "Steps : 800, Gen Loss Total : 41.929, Mel-Spec. Error : 0.248, s/b : 2.073\n",
            "Steps : 805, Gen Loss Total : 41.485, Mel-Spec. Error : 0.234, s/b : 2.072\n",
            "Steps : 810, Gen Loss Total : 41.654, Mel-Spec. Error : 0.240, s/b : 2.072\n",
            "Steps : 815, Gen Loss Total : 41.547, Mel-Spec. Error : 0.243, s/b : 2.061\n",
            "Steps : 820, Gen Loss Total : 42.010, Mel-Spec. Error : 0.251, s/b : 2.070\n",
            "Steps : 825, Gen Loss Total : 41.024, Mel-Spec. Error : 0.228, s/b : 2.072\n",
            "Steps : 830, Gen Loss Total : 41.354, Mel-Spec. Error : 0.233, s/b : 2.071\n",
            "Steps : 835, Gen Loss Total : 40.519, Mel-Spec. Error : 0.217, s/b : 2.077\n",
            "Steps : 840, Gen Loss Total : 40.712, Mel-Spec. Error : 0.223, s/b : 2.075\n",
            "Steps : 845, Gen Loss Total : 41.411, Mel-Spec. Error : 0.241, s/b : 2.072\n",
            "Steps : 850, Gen Loss Total : 41.091, Mel-Spec. Error : 0.227, s/b : 2.067\n",
            "Steps : 855, Gen Loss Total : 41.012, Mel-Spec. Error : 0.233, s/b : 2.064\n",
            "Steps : 860, Gen Loss Total : 41.615, Mel-Spec. Error : 0.242, s/b : 2.070\n",
            "Steps : 865, Gen Loss Total : 41.540, Mel-Spec. Error : 0.236, s/b : 2.068\n",
            "Steps : 870, Gen Loss Total : 40.288, Mel-Spec. Error : 0.214, s/b : 2.070\n",
            "Steps : 875, Gen Loss Total : 40.799, Mel-Spec. Error : 0.224, s/b : 2.066\n",
            "Steps : 880, Gen Loss Total : 41.405, Mel-Spec. Error : 0.235, s/b : 2.072\n",
            "Steps : 885, Gen Loss Total : 41.004, Mel-Spec. Error : 0.229, s/b : 2.068\n",
            "Steps : 890, Gen Loss Total : 40.829, Mel-Spec. Error : 0.225, s/b : 2.069\n",
            "Steps : 895, Gen Loss Total : 41.055, Mel-Spec. Error : 0.228, s/b : 2.065\n",
            "Steps : 900, Gen Loss Total : 41.826, Mel-Spec. Error : 0.241, s/b : 2.067\n",
            "Steps : 905, Gen Loss Total : 41.394, Mel-Spec. Error : 0.235, s/b : 2.064\n",
            "Steps : 910, Gen Loss Total : 41.618, Mel-Spec. Error : 0.241, s/b : 2.063\n",
            "Steps : 915, Gen Loss Total : 41.337, Mel-Spec. Error : 0.232, s/b : 2.067\n",
            "Steps : 920, Gen Loss Total : 40.762, Mel-Spec. Error : 0.221, s/b : 2.064\n",
            "Steps : 925, Gen Loss Total : 41.817, Mel-Spec. Error : 0.244, s/b : 2.061\n",
            "Steps : 930, Gen Loss Total : 41.106, Mel-Spec. Error : 0.229, s/b : 2.070\n",
            "Steps : 935, Gen Loss Total : 40.734, Mel-Spec. Error : 0.221, s/b : 2.067\n",
            "Steps : 940, Gen Loss Total : 40.826, Mel-Spec. Error : 0.227, s/b : 2.063\n",
            "Steps : 945, Gen Loss Total : 40.720, Mel-Spec. Error : 0.222, s/b : 2.069\n",
            "Steps : 950, Gen Loss Total : 40.297, Mel-Spec. Error : 0.207, s/b : 2.066\n",
            "Steps : 955, Gen Loss Total : 40.970, Mel-Spec. Error : 0.229, s/b : 2.064\n",
            "Steps : 960, Gen Loss Total : 40.947, Mel-Spec. Error : 0.229, s/b : 2.068\n",
            "Steps : 965, Gen Loss Total : 40.502, Mel-Spec. Error : 0.218, s/b : 2.070\n",
            "Time taken for epoch 5 is 338 sec\n",
            "\n",
            "Epoch: 6\n",
            "Steps : 970, Gen Loss Total : 40.808, Mel-Spec. Error : 0.225, s/b : 1.816\n",
            "Steps : 975, Gen Loss Total : 40.793, Mel-Spec. Error : 0.226, s/b : 2.070\n",
            "Steps : 980, Gen Loss Total : 41.228, Mel-Spec. Error : 0.228, s/b : 2.069\n",
            "Steps : 985, Gen Loss Total : 40.165, Mel-Spec. Error : 0.211, s/b : 2.072\n",
            "Steps : 990, Gen Loss Total : 40.979, Mel-Spec. Error : 0.224, s/b : 2.075\n",
            "Steps : 995, Gen Loss Total : 40.554, Mel-Spec. Error : 0.218, s/b : 2.068\n",
            "Steps : 1000, Gen Loss Total : 41.287, Mel-Spec. Error : 0.234, s/b : 2.076\n",
            "Saving checkpoint to cp_hifigan/g_00001000\n",
            "Complete.\n",
            "Saving checkpoint to cp_hifigan/do_00001000\n",
            "Complete.\n",
            "Steps : 1005, Gen Loss Total : 40.345, Mel-Spec. Error : 0.214, s/b : 2.063\n",
            "Steps : 1010, Gen Loss Total : 40.778, Mel-Spec. Error : 0.219, s/b : 2.086\n",
            "Steps : 1015, Gen Loss Total : 40.740, Mel-Spec. Error : 0.218, s/b : 2.102\n",
            "Steps : 1020, Gen Loss Total : 41.148, Mel-Spec. Error : 0.232, s/b : 2.089\n",
            "Steps : 1025, Gen Loss Total : 40.836, Mel-Spec. Error : 0.223, s/b : 2.075\n",
            "Steps : 1030, Gen Loss Total : 40.968, Mel-Spec. Error : 0.229, s/b : 2.067\n",
            "Steps : 1035, Gen Loss Total : 40.269, Mel-Spec. Error : 0.210, s/b : 2.066\n",
            "Steps : 1040, Gen Loss Total : 41.337, Mel-Spec. Error : 0.236, s/b : 2.057\n",
            "Steps : 1045, Gen Loss Total : 41.134, Mel-Spec. Error : 0.230, s/b : 2.063\n",
            "Steps : 1050, Gen Loss Total : 40.559, Mel-Spec. Error : 0.218, s/b : 2.066\n",
            "Steps : 1055, Gen Loss Total : 40.670, Mel-Spec. Error : 0.223, s/b : 2.068\n",
            "Steps : 1060, Gen Loss Total : 40.794, Mel-Spec. Error : 0.225, s/b : 2.073\n",
            "Steps : 1065, Gen Loss Total : 40.805, Mel-Spec. Error : 0.223, s/b : 2.074\n",
            "Steps : 1070, Gen Loss Total : 40.411, Mel-Spec. Error : 0.215, s/b : 2.072\n",
            "Steps : 1075, Gen Loss Total : 40.426, Mel-Spec. Error : 0.213, s/b : 2.071\n",
            "Steps : 1080, Gen Loss Total : 40.182, Mel-Spec. Error : 0.211, s/b : 2.071\n",
            "Steps : 1085, Gen Loss Total : 40.968, Mel-Spec. Error : 0.222, s/b : 2.076\n",
            "Steps : 1090, Gen Loss Total : 41.100, Mel-Spec. Error : 0.233, s/b : 2.074\n",
            "Steps : 1095, Gen Loss Total : 39.704, Mel-Spec. Error : 0.200, s/b : 2.073\n",
            "Steps : 1100, Gen Loss Total : 40.545, Mel-Spec. Error : 0.219, s/b : 2.074\n",
            "Steps : 1105, Gen Loss Total : 41.163, Mel-Spec. Error : 0.229, s/b : 2.073\n",
            "Steps : 1110, Gen Loss Total : 40.637, Mel-Spec. Error : 0.218, s/b : 2.068\n",
            "Steps : 1115, Gen Loss Total : 40.686, Mel-Spec. Error : 0.216, s/b : 2.073\n",
            "Steps : 1120, Gen Loss Total : 40.660, Mel-Spec. Error : 0.222, s/b : 2.071\n",
            "Steps : 1125, Gen Loss Total : 40.690, Mel-Spec. Error : 0.224, s/b : 2.060\n",
            "Steps : 1130, Gen Loss Total : 39.438, Mel-Spec. Error : 0.200, s/b : 2.067\n",
            "Steps : 1135, Gen Loss Total : 41.452, Mel-Spec. Error : 0.236, s/b : 2.068\n",
            "Steps : 1140, Gen Loss Total : 40.687, Mel-Spec. Error : 0.218, s/b : 2.063\n",
            "Steps : 1145, Gen Loss Total : 40.236, Mel-Spec. Error : 0.215, s/b : 2.070\n",
            "Steps : 1150, Gen Loss Total : 41.159, Mel-Spec. Error : 0.229, s/b : 2.071\n",
            "Steps : 1155, Gen Loss Total : 40.908, Mel-Spec. Error : 0.227, s/b : 2.072\n",
            "Steps : 1160, Gen Loss Total : 40.593, Mel-Spec. Error : 0.216, s/b : 2.072\n",
            "Time taken for epoch 6 is 352 sec\n",
            "\n",
            "Epoch: 7\n",
            "Steps : 1165, Gen Loss Total : 40.633, Mel-Spec. Error : 0.220, s/b : 2.063\n",
            "Steps : 1170, Gen Loss Total : 41.205, Mel-Spec. Error : 0.229, s/b : 2.055\n",
            "Steps : 1175, Gen Loss Total : 39.803, Mel-Spec. Error : 0.203, s/b : 2.070\n",
            "Steps : 1180, Gen Loss Total : 40.970, Mel-Spec. Error : 0.229, s/b : 2.064\n",
            "Steps : 1185, Gen Loss Total : 40.411, Mel-Spec. Error : 0.215, s/b : 2.066\n",
            "Steps : 1190, Gen Loss Total : 41.057, Mel-Spec. Error : 0.226, s/b : 2.070\n",
            "Steps : 1195, Gen Loss Total : 40.869, Mel-Spec. Error : 0.227, s/b : 2.069\n",
            "Steps : 1200, Gen Loss Total : 39.721, Mel-Spec. Error : 0.203, s/b : 2.062\n",
            "Steps : 1205, Gen Loss Total : 38.809, Mel-Spec. Error : 0.184, s/b : 2.074\n",
            "Steps : 1210, Gen Loss Total : 40.441, Mel-Spec. Error : 0.216, s/b : 2.072\n",
            "Steps : 1215, Gen Loss Total : 40.296, Mel-Spec. Error : 0.213, s/b : 2.062\n",
            "Steps : 1220, Gen Loss Total : 40.739, Mel-Spec. Error : 0.225, s/b : 2.073\n",
            "Steps : 1225, Gen Loss Total : 40.315, Mel-Spec. Error : 0.212, s/b : 2.068\n",
            "Steps : 1230, Gen Loss Total : 40.723, Mel-Spec. Error : 0.223, s/b : 2.066\n",
            "Steps : 1235, Gen Loss Total : 41.082, Mel-Spec. Error : 0.227, s/b : 2.070\n",
            "Steps : 1240, Gen Loss Total : 40.570, Mel-Spec. Error : 0.223, s/b : 2.070\n",
            "Steps : 1245, Gen Loss Total : 40.223, Mel-Spec. Error : 0.218, s/b : 2.069\n",
            "Steps : 1250, Gen Loss Total : 40.558, Mel-Spec. Error : 0.220, s/b : 2.070\n",
            "Steps : 1255, Gen Loss Total : 39.960, Mel-Spec. Error : 0.211, s/b : 2.072\n",
            "Steps : 1260, Gen Loss Total : 39.613, Mel-Spec. Error : 0.204, s/b : 2.072\n",
            "Steps : 1265, Gen Loss Total : 40.466, Mel-Spec. Error : 0.219, s/b : 2.071\n",
            "Steps : 1270, Gen Loss Total : 39.866, Mel-Spec. Error : 0.205, s/b : 2.075\n",
            "Steps : 1275, Gen Loss Total : 40.081, Mel-Spec. Error : 0.215, s/b : 2.074\n",
            "Steps : 1280, Gen Loss Total : 41.063, Mel-Spec. Error : 0.233, s/b : 2.068\n",
            "Steps : 1285, Gen Loss Total : 40.384, Mel-Spec. Error : 0.218, s/b : 2.066\n",
            "Steps : 1290, Gen Loss Total : 40.195, Mel-Spec. Error : 0.211, s/b : 2.069\n",
            "Steps : 1295, Gen Loss Total : 39.834, Mel-Spec. Error : 0.202, s/b : 2.071\n",
            "Steps : 1300, Gen Loss Total : 40.212, Mel-Spec. Error : 0.212, s/b : 2.071\n",
            "Steps : 1305, Gen Loss Total : 40.187, Mel-Spec. Error : 0.210, s/b : 2.070\n",
            "Steps : 1310, Gen Loss Total : 39.847, Mel-Spec. Error : 0.205, s/b : 2.069\n",
            "Steps : 1315, Gen Loss Total : 40.063, Mel-Spec. Error : 0.209, s/b : 2.071\n",
            "Steps : 1320, Gen Loss Total : 40.574, Mel-Spec. Error : 0.218, s/b : 2.074\n",
            "Steps : 1325, Gen Loss Total : 40.511, Mel-Spec. Error : 0.215, s/b : 2.073\n",
            "Steps : 1330, Gen Loss Total : 39.366, Mel-Spec. Error : 0.192, s/b : 2.073\n",
            "Steps : 1335, Gen Loss Total : 40.847, Mel-Spec. Error : 0.221, s/b : 2.070\n",
            "Steps : 1340, Gen Loss Total : 39.246, Mel-Spec. Error : 0.190, s/b : 2.066\n",
            "Steps : 1345, Gen Loss Total : 39.955, Mel-Spec. Error : 0.206, s/b : 2.063\n",
            "Steps : 1350, Gen Loss Total : 39.833, Mel-Spec. Error : 0.203, s/b : 2.067\n",
            "Steps : 1355, Gen Loss Total : 40.604, Mel-Spec. Error : 0.217, s/b : 2.074\n",
            "Time taken for epoch 7 is 339 sec\n",
            "\n",
            "Epoch: 8\n",
            "Steps : 1360, Gen Loss Total : 39.804, Mel-Spec. Error : 0.202, s/b : 2.068\n",
            "Steps : 1365, Gen Loss Total : 40.324, Mel-Spec. Error : 0.211, s/b : 2.070\n",
            "Steps : 1370, Gen Loss Total : 39.829, Mel-Spec. Error : 0.205, s/b : 2.065\n",
            "Steps : 1375, Gen Loss Total : 40.302, Mel-Spec. Error : 0.213, s/b : 2.074\n",
            "Steps : 1380, Gen Loss Total : 39.644, Mel-Spec. Error : 0.200, s/b : 2.074\n",
            "Steps : 1385, Gen Loss Total : 39.437, Mel-Spec. Error : 0.196, s/b : 2.064\n",
            "Steps : 1390, Gen Loss Total : 40.190, Mel-Spec. Error : 0.210, s/b : 2.071\n",
            "Steps : 1395, Gen Loss Total : 38.987, Mel-Spec. Error : 0.193, s/b : 2.075\n",
            "Steps : 1400, Gen Loss Total : 39.548, Mel-Spec. Error : 0.197, s/b : 2.072\n",
            "Steps : 1405, Gen Loss Total : 39.515, Mel-Spec. Error : 0.198, s/b : 2.071\n",
            "Steps : 1410, Gen Loss Total : 40.138, Mel-Spec. Error : 0.211, s/b : 2.072\n",
            "Steps : 1415, Gen Loss Total : 39.893, Mel-Spec. Error : 0.207, s/b : 2.074\n",
            "Steps : 1420, Gen Loss Total : 39.892, Mel-Spec. Error : 0.206, s/b : 2.072\n",
            "Steps : 1425, Gen Loss Total : 40.149, Mel-Spec. Error : 0.210, s/b : 2.067\n",
            "Steps : 1430, Gen Loss Total : 39.194, Mel-Spec. Error : 0.190, s/b : 2.065\n",
            "Steps : 1435, Gen Loss Total : 39.192, Mel-Spec. Error : 0.193, s/b : 2.073\n",
            "Steps : 1440, Gen Loss Total : 40.457, Mel-Spec. Error : 0.213, s/b : 2.070\n",
            "Steps : 1445, Gen Loss Total : 40.160, Mel-Spec. Error : 0.208, s/b : 2.064\n",
            "Steps : 1450, Gen Loss Total : 39.871, Mel-Spec. Error : 0.208, s/b : 2.068\n",
            "Steps : 1455, Gen Loss Total : 40.122, Mel-Spec. Error : 0.211, s/b : 2.070\n",
            "Steps : 1460, Gen Loss Total : 39.718, Mel-Spec. Error : 0.202, s/b : 2.066\n",
            "Steps : 1465, Gen Loss Total : 39.641, Mel-Spec. Error : 0.201, s/b : 2.073\n",
            "Steps : 1470, Gen Loss Total : 39.257, Mel-Spec. Error : 0.191, s/b : 2.071\n",
            "Steps : 1475, Gen Loss Total : 40.257, Mel-Spec. Error : 0.215, s/b : 2.068\n",
            "Steps : 1480, Gen Loss Total : 39.625, Mel-Spec. Error : 0.202, s/b : 2.067\n",
            "Steps : 1485, Gen Loss Total : 40.241, Mel-Spec. Error : 0.212, s/b : 2.069\n",
            "Steps : 1490, Gen Loss Total : 39.887, Mel-Spec. Error : 0.205, s/b : 2.074\n",
            "Steps : 1495, Gen Loss Total : 39.517, Mel-Spec. Error : 0.201, s/b : 2.070\n",
            "Steps : 1500, Gen Loss Total : 39.526, Mel-Spec. Error : 0.198, s/b : 2.069\n",
            "Steps : 1505, Gen Loss Total : 39.320, Mel-Spec. Error : 0.192, s/b : 2.075\n",
            "Steps : 1510, Gen Loss Total : 40.519, Mel-Spec. Error : 0.222, s/b : 2.069\n",
            "Steps : 1515, Gen Loss Total : 39.754, Mel-Spec. Error : 0.204, s/b : 2.072\n",
            "Steps : 1520, Gen Loss Total : 39.699, Mel-Spec. Error : 0.200, s/b : 2.070\n",
            "Steps : 1525, Gen Loss Total : 40.065, Mel-Spec. Error : 0.209, s/b : 2.065\n",
            "Steps : 1530, Gen Loss Total : 38.839, Mel-Spec. Error : 0.183, s/b : 2.069\n",
            "Steps : 1535, Gen Loss Total : 40.666, Mel-Spec. Error : 0.222, s/b : 2.068\n",
            "Steps : 1540, Gen Loss Total : 39.904, Mel-Spec. Error : 0.205, s/b : 2.074\n",
            "Steps : 1545, Gen Loss Total : 40.569, Mel-Spec. Error : 0.221, s/b : 2.071\n",
            "Steps : 1550, Gen Loss Total : 40.264, Mel-Spec. Error : 0.213, s/b : 2.070\n",
            "Time taken for epoch 8 is 339 sec\n",
            "\n",
            "Epoch: 9\n",
            "Steps : 1555, Gen Loss Total : 39.766, Mel-Spec. Error : 0.202, s/b : 2.070\n",
            "Steps : 1560, Gen Loss Total : 39.751, Mel-Spec. Error : 0.206, s/b : 2.068\n",
            "Steps : 1565, Gen Loss Total : 39.220, Mel-Spec. Error : 0.194, s/b : 2.071\n",
            "Steps : 1570, Gen Loss Total : 39.493, Mel-Spec. Error : 0.198, s/b : 2.064\n",
            "Steps : 1575, Gen Loss Total : 39.680, Mel-Spec. Error : 0.199, s/b : 2.071\n",
            "Steps : 1580, Gen Loss Total : 40.066, Mel-Spec. Error : 0.207, s/b : 2.072\n",
            "Steps : 1585, Gen Loss Total : 39.375, Mel-Spec. Error : 0.195, s/b : 2.077\n",
            "Steps : 1590, Gen Loss Total : 39.377, Mel-Spec. Error : 0.196, s/b : 2.072\n",
            "Steps : 1595, Gen Loss Total : 39.766, Mel-Spec. Error : 0.205, s/b : 2.072\n",
            "Steps : 1600, Gen Loss Total : 39.417, Mel-Spec. Error : 0.197, s/b : 2.074\n",
            "Steps : 1605, Gen Loss Total : 40.079, Mel-Spec. Error : 0.209, s/b : 2.071\n",
            "Steps : 1610, Gen Loss Total : 39.944, Mel-Spec. Error : 0.209, s/b : 2.067\n",
            "Steps : 1615, Gen Loss Total : 40.125, Mel-Spec. Error : 0.209, s/b : 2.067\n",
            "Steps : 1620, Gen Loss Total : 39.344, Mel-Spec. Error : 0.195, s/b : 2.070\n",
            "Steps : 1625, Gen Loss Total : 40.119, Mel-Spec. Error : 0.210, s/b : 2.069\n",
            "Steps : 1630, Gen Loss Total : 39.190, Mel-Spec. Error : 0.195, s/b : 2.056\n",
            "Steps : 1635, Gen Loss Total : 39.528, Mel-Spec. Error : 0.203, s/b : 2.066\n",
            "Steps : 1640, Gen Loss Total : 38.711, Mel-Spec. Error : 0.182, s/b : 2.066\n",
            "Steps : 1645, Gen Loss Total : 39.205, Mel-Spec. Error : 0.193, s/b : 2.068\n",
            "Steps : 1650, Gen Loss Total : 39.631, Mel-Spec. Error : 0.199, s/b : 2.074\n",
            "Steps : 1655, Gen Loss Total : 39.717, Mel-Spec. Error : 0.204, s/b : 2.070\n",
            "Steps : 1660, Gen Loss Total : 39.834, Mel-Spec. Error : 0.204, s/b : 2.067\n",
            "Steps : 1665, Gen Loss Total : 39.593, Mel-Spec. Error : 0.202, s/b : 2.074\n",
            "Steps : 1670, Gen Loss Total : 39.984, Mel-Spec. Error : 0.208, s/b : 2.068\n",
            "Steps : 1675, Gen Loss Total : 40.445, Mel-Spec. Error : 0.219, s/b : 2.069\n",
            "Steps : 1680, Gen Loss Total : 39.042, Mel-Spec. Error : 0.190, s/b : 2.061\n",
            "Steps : 1685, Gen Loss Total : 38.761, Mel-Spec. Error : 0.184, s/b : 2.069\n",
            "Steps : 1690, Gen Loss Total : 40.444, Mel-Spec. Error : 0.217, s/b : 2.066\n",
            "Steps : 1695, Gen Loss Total : 38.987, Mel-Spec. Error : 0.189, s/b : 2.068\n",
            "Steps : 1700, Gen Loss Total : 39.315, Mel-Spec. Error : 0.196, s/b : 2.065\n",
            "Steps : 1705, Gen Loss Total : 39.517, Mel-Spec. Error : 0.198, s/b : 2.070\n",
            "Steps : 1710, Gen Loss Total : 39.046, Mel-Spec. Error : 0.190, s/b : 2.070\n",
            "Steps : 1715, Gen Loss Total : 39.507, Mel-Spec. Error : 0.200, s/b : 2.069\n",
            "Steps : 1720, Gen Loss Total : 39.647, Mel-Spec. Error : 0.201, s/b : 2.070\n",
            "Steps : 1725, Gen Loss Total : 39.629, Mel-Spec. Error : 0.201, s/b : 2.070\n",
            "Steps : 1730, Gen Loss Total : 39.864, Mel-Spec. Error : 0.209, s/b : 2.072\n",
            "Steps : 1735, Gen Loss Total : 39.501, Mel-Spec. Error : 0.197, s/b : 2.068\n",
            "Steps : 1740, Gen Loss Total : 40.190, Mel-Spec. Error : 0.213, s/b : 2.067\n",
            "Steps : 1745, Gen Loss Total : 39.622, Mel-Spec. Error : 0.200, s/b : 2.067\n",
            "Time taken for epoch 9 is 339 sec\n",
            "\n",
            "Epoch: 10\n",
            "Steps : 1750, Gen Loss Total : 38.793, Mel-Spec. Error : 0.183, s/b : 2.066\n",
            "Steps : 1755, Gen Loss Total : 38.880, Mel-Spec. Error : 0.185, s/b : 2.064\n",
            "Steps : 1760, Gen Loss Total : 39.239, Mel-Spec. Error : 0.196, s/b : 2.067\n",
            "Steps : 1765, Gen Loss Total : 40.415, Mel-Spec. Error : 0.214, s/b : 2.065\n",
            "Steps : 1770, Gen Loss Total : 39.904, Mel-Spec. Error : 0.207, s/b : 2.066\n",
            "Steps : 1775, Gen Loss Total : 39.345, Mel-Spec. Error : 0.195, s/b : 2.067\n",
            "Steps : 1780, Gen Loss Total : 39.230, Mel-Spec. Error : 0.194, s/b : 2.066\n",
            "Steps : 1785, Gen Loss Total : 40.589, Mel-Spec. Error : 0.221, s/b : 2.070\n",
            "Steps : 1790, Gen Loss Total : 38.894, Mel-Spec. Error : 0.187, s/b : 2.068\n",
            "Steps : 1795, Gen Loss Total : 40.358, Mel-Spec. Error : 0.216, s/b : 2.069\n",
            "Steps : 1800, Gen Loss Total : 39.750, Mel-Spec. Error : 0.202, s/b : 2.061\n",
            "Steps : 1805, Gen Loss Total : 38.738, Mel-Spec. Error : 0.184, s/b : 2.068\n",
            "Steps : 1810, Gen Loss Total : 40.451, Mel-Spec. Error : 0.216, s/b : 2.067\n",
            "Steps : 1815, Gen Loss Total : 39.246, Mel-Spec. Error : 0.190, s/b : 2.069\n",
            "Steps : 1820, Gen Loss Total : 39.492, Mel-Spec. Error : 0.198, s/b : 2.070\n",
            "Steps : 1825, Gen Loss Total : 39.037, Mel-Spec. Error : 0.188, s/b : 2.071\n",
            "Steps : 1830, Gen Loss Total : 38.521, Mel-Spec. Error : 0.177, s/b : 2.063\n",
            "Steps : 1835, Gen Loss Total : 38.941, Mel-Spec. Error : 0.188, s/b : 2.067\n",
            "Steps : 1840, Gen Loss Total : 39.800, Mel-Spec. Error : 0.202, s/b : 2.068\n",
            "Steps : 1845, Gen Loss Total : 38.976, Mel-Spec. Error : 0.189, s/b : 2.061\n",
            "Steps : 1850, Gen Loss Total : 38.887, Mel-Spec. Error : 0.188, s/b : 2.066\n",
            "Steps : 1855, Gen Loss Total : 39.344, Mel-Spec. Error : 0.195, s/b : 2.070\n",
            "Steps : 1860, Gen Loss Total : 39.544, Mel-Spec. Error : 0.198, s/b : 2.069\n",
            "Steps : 1865, Gen Loss Total : 38.695, Mel-Spec. Error : 0.183, s/b : 2.067\n",
            "Steps : 1870, Gen Loss Total : 39.698, Mel-Spec. Error : 0.198, s/b : 2.068\n",
            "Steps : 1875, Gen Loss Total : 38.791, Mel-Spec. Error : 0.184, s/b : 2.058\n",
            "Steps : 1880, Gen Loss Total : 39.369, Mel-Spec. Error : 0.197, s/b : 2.067\n",
            "Steps : 1885, Gen Loss Total : 39.322, Mel-Spec. Error : 0.193, s/b : 2.072\n",
            "Steps : 1890, Gen Loss Total : 38.480, Mel-Spec. Error : 0.180, s/b : 2.064\n",
            "Steps : 1895, Gen Loss Total : 38.905, Mel-Spec. Error : 0.187, s/b : 2.067\n",
            "Steps : 1900, Gen Loss Total : 39.154, Mel-Spec. Error : 0.193, s/b : 2.069\n",
            "Steps : 1905, Gen Loss Total : 39.666, Mel-Spec. Error : 0.205, s/b : 2.068\n",
            "Steps : 1910, Gen Loss Total : 38.936, Mel-Spec. Error : 0.190, s/b : 2.070\n",
            "Steps : 1915, Gen Loss Total : 38.683, Mel-Spec. Error : 0.184, s/b : 2.071\n",
            "Steps : 1920, Gen Loss Total : 40.293, Mel-Spec. Error : 0.214, s/b : 2.068\n",
            "Steps : 1925, Gen Loss Total : 39.002, Mel-Spec. Error : 0.189, s/b : 2.069\n",
            "Steps : 1930, Gen Loss Total : 38.437, Mel-Spec. Error : 0.179, s/b : 2.064\n",
            "Steps : 1935, Gen Loss Total : 39.416, Mel-Spec. Error : 0.202, s/b : 2.068\n",
            "Time taken for epoch 10 is 338 sec\n",
            "\n",
            "Epoch: 11\n",
            "Steps : 1940, Gen Loss Total : 39.872, Mel-Spec. Error : 0.207, s/b : 1.815\n",
            "Steps : 1945, Gen Loss Total : 38.379, Mel-Spec. Error : 0.178, s/b : 2.066\n",
            "Steps : 1950, Gen Loss Total : 39.581, Mel-Spec. Error : 0.204, s/b : 2.075\n",
            "Steps : 1955, Gen Loss Total : 38.406, Mel-Spec. Error : 0.179, s/b : 2.067\n",
            "Steps : 1960, Gen Loss Total : 39.299, Mel-Spec. Error : 0.191, s/b : 2.075\n",
            "Steps : 1965, Gen Loss Total : 39.118, Mel-Spec. Error : 0.192, s/b : 2.069\n",
            "Steps : 1970, Gen Loss Total : 39.119, Mel-Spec. Error : 0.192, s/b : 2.077\n",
            "Steps : 1975, Gen Loss Total : 38.267, Mel-Spec. Error : 0.174, s/b : 2.072\n",
            "Steps : 1980, Gen Loss Total : 38.794, Mel-Spec. Error : 0.185, s/b : 2.078\n",
            "Steps : 1985, Gen Loss Total : 38.472, Mel-Spec. Error : 0.177, s/b : 2.066\n",
            "Steps : 1990, Gen Loss Total : 38.802, Mel-Spec. Error : 0.185, s/b : 2.069\n",
            "Steps : 1995, Gen Loss Total : 38.097, Mel-Spec. Error : 0.172, s/b : 2.066\n",
            "Steps : 2000, Gen Loss Total : 38.764, Mel-Spec. Error : 0.188, s/b : 2.063\n",
            "Saving checkpoint to cp_hifigan/g_00002000\n",
            "Complete.\n",
            "Saving checkpoint to cp_hifigan/do_00002000\n",
            "Complete.\n",
            "Steps : 2005, Gen Loss Total : 39.692, Mel-Spec. Error : 0.205, s/b : 2.067\n",
            "Steps : 2010, Gen Loss Total : 38.837, Mel-Spec. Error : 0.187, s/b : 2.091\n",
            "Steps : 2015, Gen Loss Total : 38.963, Mel-Spec. Error : 0.189, s/b : 2.107\n",
            "Steps : 2020, Gen Loss Total : 38.353, Mel-Spec. Error : 0.174, s/b : 2.111\n",
            "Steps : 2025, Gen Loss Total : 39.417, Mel-Spec. Error : 0.198, s/b : 2.087\n",
            "Steps : 2030, Gen Loss Total : 39.219, Mel-Spec. Error : 0.193, s/b : 2.069\n",
            "Steps : 2035, Gen Loss Total : 39.352, Mel-Spec. Error : 0.200, s/b : 2.061\n",
            "Steps : 2040, Gen Loss Total : 39.995, Mel-Spec. Error : 0.207, s/b : 2.061\n",
            "Steps : 2045, Gen Loss Total : 38.902, Mel-Spec. Error : 0.187, s/b : 2.054\n",
            "Steps : 2050, Gen Loss Total : 39.248, Mel-Spec. Error : 0.193, s/b : 2.059\n",
            "Steps : 2055, Gen Loss Total : 39.396, Mel-Spec. Error : 0.194, s/b : 2.073\n",
            "Steps : 2060, Gen Loss Total : 39.685, Mel-Spec. Error : 0.203, s/b : 2.075\n",
            "Steps : 2065, Gen Loss Total : 39.443, Mel-Spec. Error : 0.197, s/b : 2.081\n",
            "Steps : 2070, Gen Loss Total : 38.987, Mel-Spec. Error : 0.187, s/b : 2.077\n",
            "Steps : 2075, Gen Loss Total : 39.179, Mel-Spec. Error : 0.196, s/b : 2.072\n",
            "Steps : 2080, Gen Loss Total : 38.487, Mel-Spec. Error : 0.179, s/b : 2.065\n",
            "Steps : 2085, Gen Loss Total : 39.742, Mel-Spec. Error : 0.205, s/b : 2.072\n",
            "Steps : 2090, Gen Loss Total : 38.857, Mel-Spec. Error : 0.188, s/b : 2.067\n",
            "Steps : 2095, Gen Loss Total : 38.793, Mel-Spec. Error : 0.184, s/b : 2.066\n",
            "Steps : 2100, Gen Loss Total : 38.764, Mel-Spec. Error : 0.183, s/b : 2.066\n",
            "Steps : 2105, Gen Loss Total : 38.259, Mel-Spec. Error : 0.177, s/b : 2.066\n",
            "Steps : 2110, Gen Loss Total : 38.516, Mel-Spec. Error : 0.181, s/b : 2.071\n",
            "Steps : 2115, Gen Loss Total : 38.829, Mel-Spec. Error : 0.187, s/b : 2.075\n",
            "Steps : 2120, Gen Loss Total : 39.029, Mel-Spec. Error : 0.193, s/b : 2.069\n",
            "Steps : 2125, Gen Loss Total : 39.729, Mel-Spec. Error : 0.203, s/b : 2.075\n",
            "Steps : 2130, Gen Loss Total : 39.032, Mel-Spec. Error : 0.189, s/b : 2.073\n",
            "Time taken for epoch 11 is 354 sec\n",
            "\n",
            "Epoch: 12\n",
            "Steps : 2135, Gen Loss Total : 39.492, Mel-Spec. Error : 0.199, s/b : 2.071\n",
            "Steps : 2140, Gen Loss Total : 39.870, Mel-Spec. Error : 0.205, s/b : 2.073\n",
            "Steps : 2145, Gen Loss Total : 39.250, Mel-Spec. Error : 0.193, s/b : 2.073\n",
            "Steps : 2150, Gen Loss Total : 39.839, Mel-Spec. Error : 0.205, s/b : 2.079\n",
            "Steps : 2155, Gen Loss Total : 39.026, Mel-Spec. Error : 0.189, s/b : 2.074\n",
            "Steps : 2160, Gen Loss Total : 38.773, Mel-Spec. Error : 0.185, s/b : 2.062\n",
            "Steps : 2165, Gen Loss Total : 39.385, Mel-Spec. Error : 0.198, s/b : 2.072\n",
            "Steps : 2170, Gen Loss Total : 38.345, Mel-Spec. Error : 0.176, s/b : 2.063\n",
            "Steps : 2175, Gen Loss Total : 39.094, Mel-Spec. Error : 0.192, s/b : 2.068\n",
            "Steps : 2180, Gen Loss Total : 39.141, Mel-Spec. Error : 0.194, s/b : 2.071\n",
            "Steps : 2185, Gen Loss Total : 38.972, Mel-Spec. Error : 0.191, s/b : 2.061\n",
            "Steps : 2190, Gen Loss Total : 39.307, Mel-Spec. Error : 0.195, s/b : 2.066\n",
            "Steps : 2195, Gen Loss Total : 38.838, Mel-Spec. Error : 0.188, s/b : 2.070\n",
            "Steps : 2200, Gen Loss Total : 39.305, Mel-Spec. Error : 0.195, s/b : 2.066\n",
            "Steps : 2205, Gen Loss Total : 39.936, Mel-Spec. Error : 0.211, s/b : 2.072\n",
            "Steps : 2210, Gen Loss Total : 39.123, Mel-Spec. Error : 0.191, s/b : 2.057\n",
            "Steps : 2215, Gen Loss Total : 38.813, Mel-Spec. Error : 0.186, s/b : 2.059\n",
            "Steps : 2220, Gen Loss Total : 38.484, Mel-Spec. Error : 0.180, s/b : 2.065\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/hifi-gan/train.py\", line 275, in <module>\n",
            "    main()\n",
            "  File \"/content/hifi-gan/train.py\", line 271, in main\n",
            "    train(0, a, h)\n",
            "  File \"/content/hifi-gan/train.py\", line 156, in train\n",
            "    loss_gen_all.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 /content/hifi-gan/filelists/training.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7iUGPNiFaO3",
        "outputId": "f4801953-62af-4ad5-c958-618cbbd87980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_02131_16k.npy|/content/drive/MyDrive/autovc_data/wav16k/female_speaker/train_hindifullfemale_02131_16k.wav\n",
            "/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_01097_16k.npy|/content/drive/MyDrive/autovc_data/wav16k/female_speaker/train_hindifullfemale_01097_16k.wav\n",
            "/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_03475_16k.npy|/content/drive/MyDrive/autovc_data/wav16k/female_speaker/train_hindifullfemale_03475_16k.wav\n",
            "/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_05334_16k.npy|/content/drive/MyDrive/autovc_data/wav16k/female_speaker/train_hindifullfemale_05334_16k.wav\n",
            "/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_01716_16k.npy|/content/drive/MyDrive/autovc_data/wav16k/female_speaker/train_hindifullfemale_01716_16k.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxbDPkbwihjh",
        "outputId": "9b5c2dc1-9316-4856-d233-f3d0f31205ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autovc.ckpt  \u001b[0m\u001b[01;34mhifi-gan\u001b[0m/   \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mTacotron2-PyTorch\u001b[0m/\n",
            "\u001b[01;34mdrive\u001b[0m/       \u001b[01;34mmel_files\u001b[0m/  \u001b[01;34mspmel\u001b[0m/        \u001b[01;34mwav16k\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoVC Implementation\n",
        "\n"
      ],
      "metadata": {
        "id": "l5JMK3iyne0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/auspicious3000/autovc.git\n",
        "%cd autovc\n",
        "# !pip install -r requirements.txt  # If there's a requirements file\n",
        "\n",
        "# Add print statement to model_vc.py to debug freq\n",
        "!sed -i \"/def forward(self, x, c_org):/a\\ \\ \\ \\ \\ \\ \\ \\ print(f'Encoder self.freq: {self.freq}')\" model_vc.py\n",
        "# Add print statement in Generator's forward to check c_org shape\n",
        "!sed -i \"/codes = self.encoder(x, c_org)/i\\ \\ \\ \\ \\ \\ \\ \\ print(f'Generator forward - shape of c_org before encoder: {c_org.shape}')\" model_vc.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q2LiFJXRUq3",
        "outputId": "96b65a98-a555-46d9-b393-81588d2cf38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'autovc'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 116 (delta 4), reused 9 (delta 4), pack-reused 104 (from 1)\u001b[K\n",
            "Receiving objects: 100% (116/116), 8.18 MiB | 12.39 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "/content/autovc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Tacotron2 (Text → Mel)"
      ],
      "metadata": {
        "id": "rDF5TbqlgmvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/Tacotron2-PyTorch\")"
      ],
      "metadata": {
        "id": "EZS7FtLNk64W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Tacotron2-PyTorch\n",
        "!python3 inference.py --ckpt_pth=ckpt_200000 --text='Tacotron is awesome.' --npy_pth=../mel_files/1\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz74PCXz79NC",
        "outputId": "1acf98d5-7f76-472f-f4ae-004ece102200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tacotron2-PyTorch\n",
            "Terminated by gate.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Run AutoVC (Source Mel → Target Mel)"
      ],
      "metadata": {
        "id": "UoAo3qpNg6Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/autovc')  # adjust if you cloned elsewhere\n",
        "\n",
        "from model_vc import Generator\n",
        "G = Generator(dim_neck=32, dim_emb=256, dim_pre=512, freq=32).cuda()\n",
        "\n",
        "# Load the model weights\n",
        "ckpt = torch.load('/content/autovc.ckpt', map_location='cpu')\n",
        "G.load_state_dict(ckpt['model'])\n",
        "G.eval()\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def run_autovc(generator, dim_emb, source_mel_path, output_path, ref_mel_path=None, emb_org=None, emb_trg=None):\n",
        "    def pad_seq(x, base=32):\n",
        "        len_out = int(base * np.ceil(float(x.shape[1]) / base))\n",
        "        len_pad = len_out - x.shape[1]\n",
        "        if len_pad == 0:\n",
        "            return x\n",
        "        pad = np.zeros((x.shape[0], len_pad))\n",
        "        return np.concatenate((x, pad), axis=1)\n",
        "\n",
        "    content = np.load(source_mel_path)\n",
        "    print(f\"Shape of mel before padding: {content.shape}\")\n",
        "    content = pad_seq(content.T).T\n",
        "    print(f\"Shape of mel after padding: {content.shape}\")\n",
        "    content_tensor = torch.from_numpy(content).unsqueeze(0).cuda().float()\n",
        "\n",
        "    # Generate embedding\n",
        "    if ref_mel_path:\n",
        "        ref = np.load(ref_mel_path)\n",
        "        ref_tensor = torch.FloatTensor(ref).unsqueeze(0).cuda().float()\n",
        "        with torch.no_grad():\n",
        "            _, ref_emb = generator(ref_tensor, ref_tensor, ref_tensor)\n",
        "    elif emb_trg is not None:\n",
        "        ref_emb = emb_trg.unsqueeze(0).cuda().float()\n",
        "    else:\n",
        "        ref_emb = torch.randn(1, dim_emb).cuda().float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        c_org = ref_emb\n",
        "        c_trg = ref_emb\n",
        "        converted_mel, _, _ = generator(content_tensor, c_org, c_trg)\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    np.save(output_path, converted_mel.squeeze(0).cpu().numpy())\n",
        "    print(f\"Saved converted mel to: {output_path}\")\n",
        "\n",
        "source_mel = '/content/drive/MyDrive/autovc_data/spmel/female_speaker/train_hindifullfemale_00001_16k.npy'\n",
        "output_mel = '/content/converted_mels/train_hindifullfemale_00001_16k_converted.npy'\n",
        "\n",
        "run_autovc(\n",
        "    generator=G,\n",
        "    dim_emb=256,\n",
        "    source_mel_path=source_mel,\n",
        "    output_path=output_mel\n",
        ")"
      ],
      "metadata": {
        "id": "NxRGrPhGg2dQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "aaf4a41f-3863-46e6-c7d8-1880da54236d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of mel before padding: (272, 80)\n",
            "Shape of mel after padding: (288, 80)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [512, 336, 5], expected input[1, 544, 80] to have 336 channels, but got 544 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1504218172.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0moutput_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/converted_mels/train_hindifullfemale_00001_16k_converted.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m run_autovc(\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mdim_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1504218172.py\u001b[0m in \u001b[0;36mrun_autovc\u001b[0;34m(generator, dim_emb, source_mel_path, output_path, ref_mel_path, emb_org, emb_trg)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mc_org\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mc_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mconverted_mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_org\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_trg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/autovc/model_vc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, c_org, c_trg)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# --- Encoder ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_org\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# list of code tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Expand and concatenate codes along time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/autovc/model_vc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, c_org)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, T, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/autovc/model_vc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             )\n\u001b[0;32m--> 366\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 336, 5], expected input[1, 544, 80] to have 336 channels, but got 544 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. HiFi-GAN Vocoder (Mel → Wav)"
      ],
      "metadata": {
        "id": "gSGzKEG9hP02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%cd hifi-gan\n",
        "!python3 inference_e2e.py --checkpoint_file g_00002000 --input_mels_dir ../spmel/female_speaker --output_dir ../wav_files\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vV6Nmq_Gx3V",
        "outputId": "eec3df8f-f1f7-464f-fe75-49c5edda1d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hifi-gan\n",
            "Initializing Inference Process..\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "Loading 'g_00002000'\n",
            "Complete.\n",
            "Removing weight norm...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/hifi-gan/inference_e2e.py\", line 89, in <module>\n",
            "    main()\n",
            "  File \"/content/hifi-gan/inference_e2e.py\", line 85, in main\n",
            "    inference(a)\n",
            "  File \"/content/hifi-gan/inference_e2e.py\", line 50, in inference\n",
            "    y_g_hat = generator(x)\n",
            "              ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hifi-gan/models.py\", line 101, in forward\n",
            "    x = self.conv_pre(x)\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
            "    return F.conv1d(\n",
            "           ^^^^^^^^^\n",
            "RuntimeError: Given groups=1, weight of size [512, 80, 7], expected input[1, 235, 80] to have 80 channels, but got 235 channels instead\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ElzCby5HEB"
      },
      "source": [
        "## Play synthesized wav file\n",
        "### 4. Full pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"\" > /content/Tacotron2-PyTorch/utils/__init__.py"
      ],
      "metadata": {
        "id": "fbjzStnO9M4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, numpy as np, librosa\n",
        "from scipy.io.wavfile import write as wav_write\n",
        "\n",
        "# --- CONFIG ---\n",
        "TEXT = \"Tacotron is awesome.\"\n",
        "REF_WAV = \"/content/wav16k/female_speaker/train_hindifullfemale_03157_16k.wav\"   # <-- put your reference wav here\n",
        "OUT_WAV = \"/content/final_output.wav\"\n",
        "\n",
        "# === Step 1: Tacotron2 ===\n",
        "print(\"Step 1: Tacotron2...\")\n",
        "taco_mel = tts_to_mel(TEXT)  # (80, T)\n",
        "print(\"Tacotron2 mel shape:\", taco_mel.shape)\n",
        "\n",
        "# === Step 2: AutoVC ===\n",
        "# Step 2: Voice conversion\n",
        "autovc_mel = run_autovc(taco_mel)\n",
        "\n",
        "# === Step 3: HiFi-GAN ===\n",
        "print(\"Step 3: HiFi-GAN...\")\n",
        "wav = mel_to_wav(autovc_mel)\n",
        "\n",
        "# Save WAV\n",
        "wav_write(OUT_WAV, 22050, wav)\n",
        "print(\"Saved final output to:\", OUT_WAV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "gnWwGDnf0LnN",
        "outputId": "21d6412d-ab48-4b44-c156-acc1a15a7e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Tacotron2...\n",
            "Terminated by gate.\n",
            "Tacotron2 mel shape: (80, 135)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "run_autovc() missing 3 required positional arguments: 'dim_emb', 'source_mel_path', and 'output_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3617031368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# === Step 2: AutoVC ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Step 2: Voice conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mautovc_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_autovc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaco_mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# === Step 3: HiFi-GAN ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: run_autovc() missing 3 required positional arguments: 'dim_emb', 'source_mel_path', and 'output_path'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}